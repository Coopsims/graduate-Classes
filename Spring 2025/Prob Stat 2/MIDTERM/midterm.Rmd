---
title: "Midterm Exercises"
author: "Ben Funk"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggpubr)
library(lawstat)
library(GGally)
library(lmtest)
options(dplyr.summarise.inform = FALSE)
```

## Instructions

Please complete the questions on this template and upload your solutions in a single knitted Word or pdf document. Please also upload your completed template.

In light of the exam context, the data sets for the questions have been generated fairly clearly to satisfy or fairly obviously to violate the requirements of the statistical procedures. If reasonable exploratory analysis is done, there should be little ambiguity as to whether the given data satisfy the requirements. This is unrealistic, but less stressful for students and graders alike.


## Question 1

The simulated data in the files "dat1_1.RData", "dat1_2.RData", and dat1_3.RData" represent jury awards for four different case types. The dollar value of the awards are in the variable "award". An identifier for the case type is in the variable "case.type". You may assume that the awards in the data are independent samples from the population of possible awards for the given case type. 

The question of interest is whether the mean award for each case type is equal to the mean award for the other case types. One of the data sets satisfies the assumptions for an ANOVA. One of the data sets does not satisfy the assumptions for an ANOVA but fits the requirements for a Kruskal-Wallis test to be a test of the null hypothesis that the means are equal: that the population distributions of the groups differ, if at all, by the addition of a constant. One of the data sets does not meet the assumptions for either an ANOVA or a Kruskal-Wallis test as tests of the null hypothesis that the means are equal. But it does satisfy the assumptions for the Welch's ANOVA test: that each group is an independent sample from a population with a Normal distribution and that the variances of the groups are not necessarily equal.

For each of the three data sets, please perform the following tasks:


1. Perform visual or statistical diagnostics to identify the appropriate test for the null hypothesis that the means are equal. State your conclusion.


2. Perform and display only the appropriate test for the null hypothesis that the means are equal.


3. State your conclusion about the strength of the evidence that the test provides against the null for the specific data set.



### Helper function I created, this will automatically select the best test given the results of the levene and shapiro-wilks test
```{r}
diagnose_and_test <- function(df, response, group) {
  response_vec <- df[[response]]
  group_vec    <- df[[group]]

  # Normality per group
  shapiro_list <- by(response_vec, group_vec, shapiro.test)
  normal_ok    <- all(sapply(shapiro_list, \(x) x$p.value > .05))

  # Homogeneity of variances
  levene_p     <- lawstat::levene.test(response_vec, group_vec)$p.value
  equal_var    <- levene_p > .05

  # Select appropriate test
  if (normal_ok) {
    if (equal_var) {
      out <- aov(response_vec ~ group_vec)
    } else {
      out <- oneway.test(response_vec ~ group_vec)
    }
  } else {
    out <- kruskal.test(response_vec, group_vec)
  }

  list(Shapiro = shapiro_list,
       LeveneP = levene_p,
       Test    = out)
}
```





## Question 1, part 1

(10 points)

Please analyze dat1.1 as described above. For your convenience, basic syntax for each of the tests is illustrated below. Please delete the inapplicable tests.


```{r}
load(file="dat1_1.RData")
kruskal.test(dat1.1$award,dat1.1$case.type) # stats package
oneway.test(award~case.type,data=dat1.1)
summary(aov(award~case.type,data=dat1.1) )
```

### your answer here

```{r}
q1p1 <- diagnose_and_test(dat1.1, "award", "case.type")
q1p1
```
The null hypothesis that the four case-type means are equal is rejected; at least one mean award differs.

## Question 1, part 2

(10 points)


Please analyze dat1.2 as described above.

### your answer here

```{r}
load("dat1_2.RData")
q1p2 <- diagnose_and_test(dat1.2, "award", "case.type")
q1p2

```
There is no evidence that the mean award differs by case type; retain the null.


## Q1, part 3

(10 points)


Please analyze dat1.3 as described above. 

### your answer here

```{r}
load("dat1_3.RData")
q1p3 <- diagnose_and_test(dat1.3, "award", "case.type")
q1p3

```
The null of equal central tendency is rejected; median/mean awards are not equal across the four case types.


# Question 2

The simulated data in the file "dat2.RData" represent the results of a drug trial. Subjects with one of 3 disease etiologies, "disease", were recruited, then randomly assigned to one of 4 treatments, "treatment", and the amount of a biomarker assessed, "amt".



## Question 2, part 1

(5 points)

Please perform visual or statistical diagnostics to test the applicability of a 2-way ANOVA with interaction to these data. State your conclusion.

### your answer here

```{r}
load("dat2.RData")
mod_q2 <- aov(amt ~ disease * treatment, data = dat2)
summary(mod_q2)
par(mfrow = c(2, 2))
plot(mod_q2)                             
par(mfrow = c(1, 1))

shapiro.test(residuals(mod_q2))

lev_p <- lawstat::levene.test(dat2$amt,
                              interaction(dat2$disease, dat2$treatment))$p.value
lev_p


```
Since both diagnostic p-values exceed 0.05 and the residual plots look good, the two‑factor ANOVA with interaction fitted in mod_q2 satisfies the key assumptions, meaning a two-factor ANOVA with interaction is appropriate.


## Question 2, part 2

(10 points)

Please perform a 2-factor ANOVA with interaction using "amt" as the response variable and "disease" and "treatment" as the grouping variables. Please provide an interpretation of the results, taking into account your response to part 1. Please also provide a visualization of the results in the form of a profile plot.

### your answer here

```{r}
ggplot(dat2, aes(treatment, amt, colour = disease, group = disease)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun = mean, geom = "point") +
  theme_minimal()
```
Both main effects are significant and, importantly, the significant interaction (p = 0.009) shows that the size and direction of the treatment effect depends on disease etiology. When interpreting treatment differences, you must compare treatments within each disease group.


## Question 3



(10 points)

A biology team has clutches of 30 eggs from each of 5 different fish of the same species. Different clutches may have different growth rates. The team is interested in the effect of the light level (light1, light2, and light3) and the diet (diet1 and diet2) on the growth of the newly hatched fish. Each clutch is divided into 3 groups of 10 eggs. Each group is assigned to an aquarium at one of the 3 light levels. Each aquarium has a divider that separates the fish in the aquarium into 2 groups of 5 fish. Each group is assigned to one of the 2 diets. The team is interested in whether the mean growth of the fish is affected by the light level, diet, or their interaction.
Please perform an ANOVA to assess whether the data are consistent with the null hypothesis that the light level and diet are unrelated to the mean growth of the fish. Please use an error structure suited to the experimental design. What do you conclude? What is the significance level of your test?

## your answer here

```{r}
load("dat3.RData")
mod_q3 <- aov(weight ~ light * diet+ Error(clutch/light), data = dat3)
summary(mod_q3)
```
Only diet significantly alters fish growth (p = 0.035), with the same direction and magnitude regardless of light intensity. Light intensity alone and its interaction with diet have no measurable effect. Thus, management should focus on dietary formulation rather than lighting to enhance growth under the conditions tested.



# Question 4

A researcher has identified 3 scale variables, x1, x2, and x3, for a particular population that may predict whether the delivery of an infant is by cesarean section or not, an outcome variable "caesearean" that is coded as 1 for a cesarean delivery and 0 otherwise. 



## Question 4, part 1

(5 points)

Please fit a logistic regression model to the simulated data in the file "dat4.RData" using "caesarean" as the response variable and the 3 scale variables as the explanatory variables. Please display the summary of the model. 

### your answer here

```{r}
load("dat4.RData")
mod_q4 <- glm(caesarean ~ x1 + x2 + x3, data = dat4, family = binomial)
summary(mod_q4)
```


## Question 4, part 2

(5 points)

Suppose the probability of a caesarean delivery is 0.5 for a particular case. For another case with the same values of the x2 and x3, but with x1 increased by 0.2, what is the probability of a caesarean delivery in this second case? Please explain your answer.

### your answer here

```{r}
p0     <- 0.5
logit0 <- log(p0 / (1 - p0))
beta1  <- coef(mod_q4)["x1"]
logit1 <- logit0 + 0.2 * beta1
p1     <- exp(logit1) / (1 + exp(logit1))
p1
```
Raising x1 by 0.2  moves the log-odds by 0.2 × (–1.2292)=–0.246. The baseline probability of 0.5 falls to 0.44

# Question 5

The data sets "dat5.train" and "dat5.test" have 5 numeric explanatory variables, x1, x2, through x5, and a numeric outcome variable, y.


## Question 5, part 1

(10 points)

Please fit a regression model of y on x1 through x5 and their pairwise interactions, m.big. Please display the summary and the usual diagnostic plots. Do the diagnostic plots indicate that the assumptions of a linear model are satisfied?

### your answer here

```{r}
load("dat5_train.RData")
train_df <- dat5.train

m.big <- lm(y ~ (x1 + x2 + x3 + x4 + x5)^2, data = train_df)
summary(m.big)
par(mfrow = c(2, 2)); plot(m.big)
```
Assumptions are largely OK given the plot of the residuals. The Model explains ~35 % of variance which is not fantastic.



## Question 5, part 2

(5 points)

Please fit a forward selection model based on AIC with m.big as the maximal model and the intercept-only model as the minimal model. While developing the model, you may want to look at the full output, but please set "trace=FALSE" when knitting your midterm. Display the summary and the usual diagnostic plots. Do the diagnostic plots indicate that the assumptions for this linear model are satisfied? 

### your answer here

```{r}
m.null <- lm(y ~ 1, data = train_df)
m.fwd  <- step(m.null,
               scope = list(lower = formula(m.null),
                            upper  = formula(m.big)),
               direction = "forward",
               trace = FALSE)
summary(m.fwd)
par(mfrow = c(2, 2)); plot(m.fwd)
```
Forward selection retained only the intercept because no term reduced AIC below 23.7. The forward AIC adds no predictive value beyond the mean.The residuals are just lines except for the QQ which is approx norm.

## Question 5, part 3

(5 points)

Please fit a backward selection model based on AIC with m.big as the maximal model and the intercept-only model as the minimal model. While developing the model, you may want to look at the full output, but please set "trace=FALSE" when knitting your midterm. Display the summary and the usual diagnostic plots. Do the diagnostic plots indicate that the hypotheses assumptions this linear model are satisfied?

### your answer here

```{r}
m.back <- step(m.big, direction = "backward", trace = FALSE)
summary(m.back)
par(mfrow = c(2, 2)); plot(m.back)
```
Slightly simpler than full model with comparable fit, no serious violations found in the residuals


## Question 5, part 4

(5 points)

Still using x1 through x5 and their pairwise interactions, please identify the best subsets of variables for models with these explanatory variables. You don't need to print out all the models. Please display the best subset model for the number of variables that results in the lowest BIC among these models. Do the diagnostic plots indicate that the hypotheses of the linear model for y based on iid Normal errors are satisfied?

### your answer here

```{r}
library(leaps)
Xmat       <- model.matrix(m.big)[, -1]
best_sub   <- regsubsets(Xmat, train_df$y,
                         nbest = 1, nvmax = ncol(Xmat), method = "exhaustive")
best_info  <- summary(best_sub)
best_size  <- which.min(best_info$bic)
best_coef  <- coef(best_sub, best_size)
best_vars  <- names(best_coef)[-1]
form_best  <- as.formula(paste("y ~", paste(best_vars, collapse = " + ")))
m.bic      <- lm(form_best, data = train_df)
summary(m.bic)
par(mfrow = c(2, 2)); plot(m.bic)
```
Most parsimonious of the competitive models was found, residuals all look fine 


## Question 5, part 5

(5 points)

Is the model using all the variables and their pairwise interactions a statistically significant improvement on the forward model?

Is the model using all the variables, pairwise interactions and squares a statistically significant improvement on the best subset model for the number of variables that results in the lowest BIC among these models?

### your answer here

```{r}
anova(m.fwd, m.big)

anova(m.bic, m.big)
```


Full vs Forward: The full model is a highly significant improvement.

Full vs Best-subset: an F-test (df = 11, 84) produces p > 0.05, meaning the extra terms in m.big do not meaningfully improve fit relative to the BIC model.

## Question 5, part 6

(5 points)

Please examine the mean square errors on the test data for the forward model, the best subset model, the backward model and the model using all the variables and their pairwise interactions. On the basis of the mean square errors, which model would you select?

### your answer here

```{r}
load("dat5_test.RData")

test_df <- dat5.test

mse <- function(actual, pred) mean((actual - pred)^2)

mse_results <- tibble(
  model = c("big", "forward", "backward", "bic"),
  mse   = c(
    mse(test_df$y, predict(m.big,  newdata = test_df)),
    mse(test_df$y, predict(m.fwd,  newdata = test_df)),
    mse(test_df$y, predict(m.back, newdata = test_df)),
    mse(test_df$y, predict(m.bic,  newdata = test_df))
  )
)
mse_results
```
The best-subset BIC model achieves the lowest prediction error and is also the most concise, so it would be the recommended model for future use.
